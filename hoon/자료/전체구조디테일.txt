1. CNN Encoder:

InceptionV3 - 이미지 특성 추출을 위한 사전 훈련된 CNN 모델
              symmetric(대칭) and asymmetric(비대칭) building blocks including convolutions, average pooling, max pooling, concatenations, dropouts, and fully connected layers
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2. Transfoermer

    2-1. Transformer Encoder :

        (1) 임베딩과 Self-Attention의 결합: Transformer의 Encoder는 먼저 입력 시퀀스[1]의 각 요소(예: 단어 또는 픽셀)를 임베딩합니다.
            이 임베딩된 표현은 입력 데이터를 고차원 벡터 공간으로 매핑하며, 이 과정에서 단어 간의 의미적 관계가 포착됩니다. 그런 다음, self-attention[2] 메커니즘을 사용하여 임베딩된 표현 간의 상호작용을 모델링합니다.

        (2) Self-Attention의 중요성: Self-attention은 입력 시퀀스의 각 요소 간의 상호작용을 계산하는 데 사용됩니다. 이를 통해 모델은 주어진 요소가 전체 시퀀스의 어느 부분과 관련이 있는지를 동적으로 파악할 수 있습니다. 
            이러한 동적인 관계 모델링은 문맥을 파악하고 각 요소의 중요성을 학습하는 데 중요합니다.
            
        (3) 다중 레이어의 활용: Transformer의 Encoder는 일반적으로 여러 개의 self-attention 레이어로 구성됩니다. 이러한 다중 레이어 구조를 통해 모델은 입력 시퀀스의 다양한 관점을 고려하고, 더욱 복잡한 상호작용을 모델링할 수 있습니다. 
            또한 각 self-attention 레이어 다음에는 피드포워드 신경망이 있어 입력 시퀀스의 각 위치에 대한 정보를 더 깊게 처리할 수 있습니다.
        
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
3. Transformer Decoder

