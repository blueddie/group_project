[출처] https://codingopera.tistory.com/41
Attention이란 문맥에 따라 집중할 단어를 결정하는 방식을 의미합니다.

Attention 모델의 구조
Encoder와 Decoder

대부분의 자연어 모델은 Encoder와 Decoder로 구성이 되어있습니다. Encoder는 입력으로 input data를 받아 압축 데이터(context vector)로 변환 및 출력해주는 역할을 합니다.
Decoder는 반대로 압축 데이터(context vector)를 입력 받아 output data를 출력해줍니다. 이는 우리가 사용하는 전화기의 원리와 동일한데, 이렇게 해주는 이유는 정보를 압축하므로써 연산량을 최소화하기 위해서입니다.

